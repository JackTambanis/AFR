<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>iPad Object Detector</title>
<style>
  body {
    margin:0;
    display:flex;
    flex-direction:column;
    align-items:center;
    background:#111;
    color:#eee;
    font-family:sans-serif;
  }
  #container {
    position:relative;
    width:90vw;
    max-width:640px;
    margin-top:20px;
    border:2px solid #444;
    overflow:hidden;
    background:#000;
  }
  video {
    position:absolute;
    top:0;
    left:0;
    width:100%;
    height:100%;
    object-fit:cover;
    z-index:1;
  }
  canvas {
    position:absolute;
    top:0;
    left:0;
    width:100%;
    height:100%;
    object-fit:cover;
    z-index:2;
    pointer-events:none;
    background:transparent;
  }
  #legend { margin-top:16px; text-align:center; }
</style>
</head>
<body>
<h1>iPad Object Detector</h1>
<p>Allow camera access. Boxes and labels detected objects in real time.</p>

<div id="container">
  <video id="video" autoplay muted playsinline></video>
  <canvas id="overlay"></canvas>
</div>
<div id="legend">Loading model…</div>

<!-- TensorFlow.js and COCO-SSD -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.20.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js"></script>

<script>
const video = document.getElementById('video');
const canvas = document.getElementById('overlay');
const container = document.getElementById('container');
const legend = document.getElementById('legend');
const ctx = canvas.getContext('2d');

async function setup() {
  try {
    legend.textContent = "Loading COCO-SSD model…";
    const model = await cocoSsd.load();
    legend.textContent = "Model loaded. Starting camera…";

    const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } });
    video.srcObject = stream;

    video.addEventListener('loadedmetadata', () => {
      video.play();
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      container.style.height = video.videoHeight + 'px';
      detectLoop(model);
    });
  } catch(err) {
    legend.textContent = "Camera error: " + err.message;
  }
}

async function detectLoop(model) {
  if (video.readyState !== 4) { requestAnimationFrame(() => detectLoop(model)); return; }

  const predictions = await model.detect(video);

  ctx.clearRect(0,0,canvas.width,canvas.height);

  predictions.forEach(pred => {
    const [x, y, width, height] = pred.bbox;

    // Draw bounding box
    ctx.strokeStyle = '#0f0';
    ctx.lineWidth = 2;
    ctx.strokeRect(x, y, width, height);

    // Draw label + score
    const text = `${pred.class}: ${(pred.score*100).toFixed(1)}%`;
    ctx.fillStyle = '#0f0';
    ctx.font = '16px sans-serif';
    ctx.fillText(text, x, y > 20 ? y-5 : y+15);
  });

  legend.textContent = predictions.length === 0 ? "No objects detected" : `Detected ${predictions.length} object(s)`;

  requestAnimationFrame(() => detectLoop(model));
}

setup();
</script>
</body>
</html>
