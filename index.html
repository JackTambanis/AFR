<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Face & Wireframe Split</title>
<style>
  html, body {
    margin: 0;
    height: 100%;
    overflow: hidden;
    background: #000;
  }
  #container {
    display: flex;
    width: 100%;
    height: 100%;
  }
  #left, #right {
    position: relative;
    flex: 1;
  }
  #video {
    width: 100%;
    height: 100%;
    object-fit: cover;
  }
  canvas {
    position: absolute;
    top: 0;
    left: 0;
  }
</style>
</head>
<body>
<div id="container">
  <div id="left">
    <video id="video" autoplay muted></video>
    <canvas id="overlayLeft"></canvas>
  </div>
  <div id="right">
    <canvas id="overlayRight"></canvas>
  </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/face-api.js/dist/face-api.min.js"></script>
<script>
window.addEventListener('DOMContentLoaded', async () => {
  const video = document.getElementById('video');
  const overlayLeft = document.getElementById('overlayLeft');
  const overlayRight = document.getElementById('overlayRight');
  const ctxLeft = overlayLeft.getContext('2d');
  const ctxRight = overlayRight.getContext('2d');

  await Promise.all([
    faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights'),
    faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights'),
    faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights')
  ]);

  navigator.mediaDevices.getUserMedia({ video: {} })
    .then(stream => video.srcObject = stream)
    .catch(err => console.error('Error accessing webcam:', err));

  video.addEventListener('play', () => {
    overlayLeft.width = video.videoWidth;
    overlayLeft.height = video.videoHeight;
    overlayRight.width = overlayLeft.width;
    overlayRight.height = overlayLeft.height;

    const displaySize = { width: video.videoWidth, height: video.videoHeight };
    faceapi.matchDimensions(overlayLeft, displaySize);
    faceapi.matchDimensions(overlayRight, displaySize);

    const scaleRight = 2; // make wireframe larger on right canvas

    setInterval(async () => {
      const detections = await faceapi
        .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions({ inputSize: 224, scoreThreshold: 0.5 }))
        .withFaceLandmarks()
        .withFaceExpressions();

      const resized = faceapi.resizeResults(detections, displaySize);

      // Clear canvases
      ctxLeft.clearRect(0,0,overlayLeft.width, overlayLeft.height);
      ctxRight.clearRect(0,0,overlayRight.width, overlayRight.height);

      // Left: bounding boxes + expressions
      faceapi.draw.drawDetections(overlayLeft, resized);
      faceapi.draw.drawFaceExpressions(overlayLeft, resized);

      // Right: wireframe lines
      resized.forEach(det => {
        const lm = det.landmarks;
        ctxRight.strokeStyle = '#0f0';
        ctxRight.lineWidth = 2;

        function drawLine(points){
          ctxRight.beginPath();
          ctxRight.moveTo(points[0].x*scaleRight, points[0].y*scaleRight);
          for(let i=1;i<points.length;i++){
            ctxRight.lineTo(points[i].x*scaleRight, points[i].y*scaleRight);
          }
          ctxRight.stroke();
        }

        drawLine(lm.getJawOutline());
        drawLine(lm.getLeftEye());
        drawLine(lm.getRightEye());
        drawLine(lm.getLeftEyebrow());
        drawLine(lm.getRightEyebrow());
        drawLine(lm.getNose());
        drawLine(lm.getMouth());
      });
    }, 100);
  });
});
</script>
</body>
</html>
