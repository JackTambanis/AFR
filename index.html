<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Face & Landmark Split</title>
<style>
  html, body {
    margin: 0;
    height: 100%;
    overflow: hidden;
    background: #000;
  }
  #container {
    display: flex;
    width: 100%;
    height: 100%;
  }
  #left, #right {
    position: relative;
    flex: 1;
  }
  #video {
    width: 100%;
    height: 100%;
    object-fit: cover;
  }
  canvas {
    position: absolute;
    top: 0;
    left: 0;
  }
</style>
</head>
<body>
<div id="container">
  <!-- Left half: video + bounding boxes + labels -->
  <div id="left">
    <video id="video" autoplay muted></video>
    <canvas id="overlayLeft"></canvas>
  </div>
  <!-- Right half: blank background + landmark tracking -->
  <div id="right">
    <canvas id="overlayRight"></canvas>
  </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/face-api.js/dist/face-api.min.js"></script>
<script>
window.addEventListener('DOMContentLoaded', async () => {
  const video = document.getElementById('video');
  const overlayLeft = document.getElementById('overlayLeft');
  const overlayRight = document.getElementById('overlayRight');
  const ctxLeft = overlayLeft.getContext('2d');
  const ctxRight = overlayRight.getContext('2d');

  // Load models
  await Promise.all([
    faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights'),
    faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights'),
    faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights')
  ]);

  // Start webcam
  navigator.mediaDevices.getUserMedia({ video: {} })
    .then(stream => video.srcObject = stream)
    .catch(err => console.error('Error accessing webcam:', err));

  video.addEventListener('play', () => {
    // Set canvas size
    overlayLeft.width = video.videoWidth;
    overlayLeft.height = video.videoHeight;
    overlayRight.width = overlayLeft.width;
    overlayRight.height = overlayLeft.height;

    const displaySize = { width: overlayLeft.width, height: overlayLeft.height };
    faceapi.matchDimensions(overlayLeft, displaySize);
    faceapi.matchDimensions(overlayRight, displaySize);

    setInterval(async () => {
      const detections = await faceapi
        .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions({ inputSize: 224, scoreThreshold: 0.5 }))
        .withFaceLandmarks()
        .withFaceExpressions();

      const resized = faceapi.resizeResults(detections, displaySize);

      // Clear both canvases
      ctxLeft.clearRect(0, 0, overlayLeft.width, overlayLeft.height);
      ctxRight.clearRect(0, 0, overlayRight.width, overlayRight.height);

      // Draw left: video + bounding boxes + expressions
      faceapi.draw.drawDetections(overlayLeft, resized);
      faceapi.draw.drawFaceExpressions(overlayLeft, resized);

      // Draw right: blank + landmarks only
      resized.forEach(det => {
        const points = det.landmarks.positions;
        ctxRight.strokeStyle = '#0f0';
        ctxRight.lineWidth = 2;
        points.forEach(p => {
          ctxRight.beginPath();
          ctxRight.arc(p.x, p.y, 2, 0, Math.PI*2);
          ctxRight.stroke();
        });
      });
    }, 100);
  });
});
</script>
</body>
</html>
