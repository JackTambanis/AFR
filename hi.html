<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Face & Expression Wireframe</title>
<style>
  html, body { margin: 0; height: 100%; overflow: hidden; background: #000; }
  #container { display: flex; width: 100%; height: 100%; }
  #left, #right { position: relative; flex: 1; }
  #video { width: 100%; height: 100%; object-fit: cover; }
  canvas { position: absolute; top: 0; left: 0; }
</style>
</head>
<body>
<div id="container">
  <div id="left">
    <video id="video" autoplay muted></video>
    <canvas id="overlayLeft"></canvas>
  </div>
  <div id="right">
    <canvas id="overlayRight"></canvas>
  </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/face-api.js/dist/face-api.min.js"></script>
<script>
window.addEventListener('DOMContentLoaded', async () => {
  const video = document.getElementById('video');
  const overlayLeft = document.getElementById('overlayLeft');
  const overlayRight = document.getElementById('overlayRight');
  const ctxLeft = overlayLeft.getContext('2d');
  const ctxRight = overlayRight.getContext('2d');

  await Promise.all([
    faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights'),
    faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights'),
    faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights')
  ]);

  navigator.mediaDevices.getUserMedia({ video: {} })
    .then(stream => video.srcObject = stream)
    .catch(err => console.error('Error accessing webcam:', err));

  let previousJaw = null;

  function lerp(a, b, t){ return a + (b - a) * t; }
  function smoothLandmarks(current, previous, t=0.3){
    if(!previous) return current.map(p => ({x: p.x, y: p.y}));
    return current.map((p, i) => ({ x: lerp(previous[i].x, p.x, t), y: lerp(previous[i].y, p.y, t) }));
  }

  const featureIndices = {
    jaw: [...Array(17).keys()],
    leftEyebrow: [...Array(5).keys()].map(i => i + 17),
    rightEyebrow: [...Array(5).keys()].map(i => i + 22),
    nose: [...Array(9).keys()].map(i => i + 27),
    leftEye: [...Array(6).keys()].map(i => i + 36),
    rightEye: [...Array(6).keys()].map(i => i + 42),
    mouth: [...Array(20).keys()].map(i => i + 48)
  };

  function extractFeature(points, indices){ return indices.map(i => points[i]); }

  video.addEventListener('play', () => {
    const displaySize = { width: video.offsetWidth, height: video.offsetHeight };
    overlayLeft.width = displaySize.width;
    overlayLeft.height = displaySize.height;
    overlayRight.width = displaySize.width;
    overlayRight.height = displaySize.height;

    faceapi.matchDimensions(overlayLeft, displaySize);

    setInterval(async () => {
      const detections = await faceapi
        .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions({ inputSize: 224, scoreThreshold: 0.5 }))
        .withFaceLandmarks()
        .withFaceExpressions();

      const resized = faceapi.resizeResults(detections, displaySize);

      ctxLeft.clearRect(0,0,overlayLeft.width, overlayLeft.height);
      ctxRight.clearRect(0,0,overlayRight.width, overlayRight.height);

      faceapi.draw.drawDetections(overlayLeft, resized);
      faceapi.draw.drawFaceExpressions(overlayLeft, resized);

      resized.forEach(det => {
        const lm = det.landmarks;
        const smoothedJaw = smoothLandmarks(extractFeature(lm.positions, featureIndices.jaw), previousJaw, 0.2);
        previousJaw = smoothedJaw;

        const leftEyebrow = extractFeature(lm.positions, featureIndices.leftEyebrow);
        const rightEyebrow = extractFeature(lm.positions, featureIndices.rightEyebrow);
        const leftEye = extractFeature(lm.positions, featureIndices.leftEye);
        const rightEye = extractFeature(lm.positions, featureIndices.rightEye);
        const nose = extractFeature(lm.positions, featureIndices.nose);
        const mouth = extractFeature(lm.positions, featureIndices.mouth);

        function drawLine(points, color='#0f0', width=2){
          if(points.length === 0) return;
          ctxRight.beginPath();
          ctxRight.strokeStyle = color;
          ctxRight.lineWidth = width;
          ctxRight.moveTo(points[0].x, points[0].y);
          for(let i=1;i<points.length;i++){
            ctxRight.lineTo(points[i].x, points[i].y);
          }
          ctxRight.stroke();
        }

        // Draw all features with minimal smoothing on expressive parts
        drawLine(smoothedJaw);
        drawLine(leftEyebrow, (leftEye[1].y - leftEyebrow[4].y > 2) ? '#ff0' : '#0f0', 2);
        drawLine(rightEyebrow, (rightEye[1].y - rightEyebrow[4].y > 2) ? '#ff0' : '#0f0', 2);
        drawLine(leftEye);
        drawLine(rightEye);
        drawLine(nose);
        drawLine(mouth, (mouth[13].y - mouth[19].y > 2) ? '#f00' : '#0f0', 2);
      });
    }, 33); // ~30fps for smoother appearance
  });
});
</script>
</body>
</html>
