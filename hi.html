<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Face & Expression Wireframe</title>
<style>
  html, body {
    margin: 0;
    height: 100%;
    overflow: hidden;
    background: #000;
  }
  #container {
    display: flex;
    width: 100%;
    height: 100%;
  }
  #left, #right {
    position: relative;
    flex: 1;
  }
  #video {
    width: 100%;
    height: 100%;
    object-fit: cover;
  }
  canvas {
    position: absolute;
    top: 0;
    left: 0;
  }
</style>
</head>
<body>
<div id="container">
  <div id="left">
    <video id="video" autoplay muted></video>
    <canvas id="overlayLeft"></canvas>
  </div>
  <div id="right">
    <canvas id="overlayRight"></canvas>
  </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/face-api.js/dist/face-api.min.js"></script>
<script>
window.addEventListener('DOMContentLoaded', async () => {
  const video = document.getElementById('video');
  const overlayLeft = document.getElementById('overlayLeft');
  const overlayRight = document.getElementById('overlayRight');
  const ctxLeft = overlayLeft.getContext('2d');
  const ctxRight = overlayRight.getContext('2d');

  await Promise.all([
    faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights'),
    faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights'),
    faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights')
  ]);

  navigator.mediaDevices.getUserMedia({ video: {} })
    .then(stream => video.srcObject = stream)
    .catch(err => console.error('Error accessing webcam:', err));

  let previousLandmarks = null;

  function lerp(a, b, t){ return a + (b - a) * t; }
  function smoothLandmarks(current, previous, t=0.5){
    if(!previous) return current.map(p => ({x: p.x, y: p.y}));
    return current.map((p, i) => ({ x: lerp(previous[i].x, p.x, t), y: lerp(previous[i].y, p.y, t) }));
  }

  video.addEventListener('play', () => {
    function updateCanvasSizes(){
      const displaySize = { width: video.offsetWidth, height: video.offsetHeight };
      overlayLeft.width = displaySize.width;
      overlayLeft.height = displaySize.height;
      overlayRight.width = displaySize.width;
      overlayRight.height = displaySize.height;
      return displaySize;
    }

    const displaySize = updateCanvasSizes();
    faceapi.matchDimensions(overlayLeft, displaySize);
    faceapi.matchDimensions(overlayRight, displaySize);

    setInterval(async () => {
      const detections = await faceapi
        .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions({ inputSize: 224, scoreThreshold: 0.5 }))
        .withFaceLandmarks()
        .withFaceExpressions();

      const resized = faceapi.resizeResults(detections, displaySize);

      ctxLeft.clearRect(0,0,overlayLeft.width, overlayLeft.height);
      ctxRight.clearRect(0,0,overlayRight.width, overlayRight.height);

      // Left: bounding boxes + expressions
      faceapi.draw.drawDetections(overlayLeft, resized);
      faceapi.draw.drawFaceExpressions(overlayLeft, resized);

      // Right: wireframe face
      resized.forEach(det => {
        const lm = det.landmarks;
        const smoothed = smoothLandmarks(lm.positions, previousLandmarks);
        previousLandmarks = smoothed;

        const xs = smoothed.map(p => p.x);
        const ys = smoothed.map(p => p.y);
        const minX = Math.min(...xs);
        const minY = Math.min(...ys);
        const maxX = Math.max(...xs);
        const maxY = Math.max(...ys);

        const scaleX = overlayRight.width / (maxX - minX) * 0.8;
        const scaleY = overlayRight.height / (maxY - minY) * 0.8;
        const offsetX = (overlayRight.width - (maxX - minX) * scaleX)/2 - minX*scaleX;
        const offsetY = (overlayRight.height - (maxY - minY) * scaleY)/2 - minY*scaleY;

        function drawLine(points, color='#0f0', width=2){
          ctxRight.beginPath();
          ctxRight.strokeStyle = color;
          ctxRight.lineWidth = width;
          ctxRight.moveTo(points[0].x*scaleX + offsetX, points[0].y*scaleY + offsetY);
          for(let i=1;i<points.length;i++){
            ctxRight.lineTo(points[i].x*scaleX + offsetX, points[i].y*scaleY + offsetY);
          }
          ctxRight.stroke();
        }

        // Eyebrow raise detection
        const leftEyebrow = lm.getLeftEyebrow();
        const rightEyebrow = lm.getRightEyebrow();
        const leftEye = lm.getLeftEye();
        const rightEye = lm.getRightEye();
        const eyebrowRaiseLeft = leftEye[1].y - leftEyebrow[4].y;
        const eyebrowRaiseRight = rightEye[1].y - rightEyebrow[4].y;
        const eyebrowColor = (eyebrowRaiseLeft > 5 || eyebrowRaiseRight > 5) ? '#ff0' : '#0f0';

        // Mouth open detection
        const mouth = lm.getMouth();
        const mouthOpen = mouth[13].y - mouth[19].y;
        const mouthColor = mouthOpen > 5 ? '#f00' : '#0f0';

        // Draw features
        drawLine(lm.getJawOutline());
        drawLine(leftEyebrow, eyebrowColor);
        drawLine(rightEyebrow, eyebrowColor);
        drawLine(leftEye);
        drawLine(rightEye);
        drawLine(lm.getNose());
        drawLine(mouth, mouthColor);
      });
    }, 50);
  });
});
</script>
</body>
</html>
